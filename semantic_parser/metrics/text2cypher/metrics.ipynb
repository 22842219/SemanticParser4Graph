{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/metrics/text2cypher/BLEU/text2cypher\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/metrics/text2cypher/BLEU/text2cypher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  json\n",
    "from Levenshtein import ratio, distance\n",
    "\n",
    "\n",
    "\n",
    "CodeT5_base_prefix_text2cypher =  '/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/output/ms/CodeT5_base_prefix_text2cypher/predictions_predict.json'\n",
    "\n",
    "json_files=[]\n",
    "models=[]\n",
    "for each in [CodeT5_base_prefix_text2cypher]:\n",
    "    json_files.append(each)\n",
    "    models.append(each.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8920334025879239\n",
      "12460\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    with open(json_files[i], 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        total_ratio_cased = 0\n",
    "        total_distance=0\n",
    "        for each in data:\n",
    "            pred = each['prediction']\n",
    "            gold = each['query']\n",
    "            total_ratio_cased+=ratio(pred, gold)\n",
    "            total_distance+=distance(pred.lower(), gold.lower())\n",
    "            gold = gold.replace('\\n', ' ')\n",
    "            with open('{}.ref.detok.txt'.format(model), 'a') as out:\n",
    "                out.write(gold)\n",
    "                out.write('\\n')\n",
    "            with open('{}.out.detok.txt'.format(model), 'a') as out:\n",
    "                out.write(pred)\n",
    "                out.write('\\n')   \n",
    "        print(total_ratio_cased/len(data))\n",
    "        print(total_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'BLEU/text2cypher'\n",
      "/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/metrics/text2cypher/BLEU/text2cypher\n"
     ]
    }
   ],
   "source": [
    "%cd BLEU/text2cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.0753\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#CodeT5_base_prefix_text2cypher\n",
    "!sacrebleu CodeT5_base_prefix_text2cypher.ref.detok.txt -i CodeT5_base_prefix_text2cypher.out.detok.txt -m bleu -b -w 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text2sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/metrics/text2cypher/BLEU/text2sql\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/metrics/text2cypher/BLEU/text2sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import  json\n",
    "from Levenshtein import ratio, distance\n",
    "\n",
    "CodeT5_base_prefix_text2sql =  '/home/22842219/Desktop/phd/SemanticParser4Graph/application/rel_db2kg/text2sql/pricai/CodeT5_base_prefix_spider_with_cell_value/predictions_predict.json'\n",
    "\n",
    "text2sql_json_files=[]\n",
    "text2sql_models=[]\n",
    "for each in [CodeT5_base_prefix_text2sql]:\n",
    "    text2sql_json_files.append(each)\n",
    "    text2sql_models.append(each.split('/')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5788735896809095\n",
      "12493\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(text2sql_models):\n",
    "\n",
    "    with open(text2sql_json_files[i], 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        total_ratio_cased = 0\n",
    "        total_distance=0\n",
    "        for each in data:\n",
    "            pred = each['prediction']\n",
    "            gold = each['query']\n",
    "            total_ratio_cased+=ratio(pred, gold)\n",
    "            total_distance+=distance(pred.lower(), gold.lower())\n",
    "            gold = gold.replace('\\n', ' ')\n",
    "            with open('{}.ref.detok.txt'.format(model), 'a') as out:\n",
    "                out.write(gold)\n",
    "                out.write('\\n')\n",
    "            with open('{}.out.detok.txt'.format(model), 'a') as out:\n",
    "                out.write(pred)\n",
    "                out.write('\\n')   \n",
    "        print(total_ratio_cased/len(data))\n",
    "        print(total_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'BLEU/text2sql'\n",
      "/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/metrics/text2cypher/BLEU/text2sql\n"
     ]
    }
   ],
   "source": [
    "%cd BLEU/text2sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.7756\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#CodeT5_base_prefix_spider_with_cell_value\n",
    "!sacrebleu CodeT5_base_prefix_spider_with_cell_value.ref.detok.txt -i CodeT5_base_prefix_spider_with_cell_value.out.detok.txt -m bleu -b -w 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sql2cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/metrics/text2cypher/BLEU/text2sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

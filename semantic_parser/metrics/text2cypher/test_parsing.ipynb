{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Cypher](https://neo4j.com/product/cypher-graph-query-language/)\n",
    "\n",
    "Cypher is a graph-optimized query language that understands, and takes advantage of, data connections. It follows connections – in any direction – to reveal previously unknown relationships and clusters. Cypher queries are much easier to write than massive SQL joins. Compare this Cypher query to its equivalent in SQL.\n",
    "\n",
    "Neo4j and Cypher Under the Hood\n",
    "\n",
    "Cypher is an expressive language with advanced graph patterns and collection support. Under the hood, the cypher processing pipeline first parses the query if not in cache, then goes through semantic verification and rewriting of the AST, followed by finding the cheapest execution plan (logical and physical) for all the operations using available planners, all the way to query execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from pygments.lexers import get_lexer_by_name\n",
    "from cypher_parser import CyqueryStatmentParser\n",
    "lexer = get_lexer_by_name(\"py2neo.cypher\")\n",
    "\n",
    "alias_pattern = re.compile(r'(t[1-9]|[a-z])')\t\n",
    "labels_pattern = re.compile(r':`[a-z|A-Z].*`')\n",
    "\n",
    "from process_cypher import CLAUSE_KEYWORDS, CYPHER_OPERATORS, WHERE_OPS, UNIT_OPS, AGG_OPS, ORDER_OPS, TABLE_TYPE, DerivedFieldAliasError, DerivedTableAliasError, ParenthesesInConditionError, ValueListError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schema file path\n",
    "# fpath = '/home/22842219/Desktop/openSource/UnifiedSKGG-Cypher/data/text2cypher/schema.json'\n",
    "fpath ='/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/data/text2cypher/schema.json'\n",
    "db_id = 'concert_singer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'*': 0,\n",
       " '`concert_singer.stadium`.Name': 1,\n",
       " '`concert_singer.stadium`.Lowest': 2,\n",
       " '`concert_singer.stadium`.Stadium_ID': 3,\n",
       " '`concert_singer.stadium`.Capacity': 4,\n",
       " '`concert_singer.stadium`.Highest': 5,\n",
       " '`concert_singer.stadium`.Location': 6,\n",
       " '`concert_singer.stadium`.Average': 7,\n",
       " '`concert_singer.singer`.Country': 8,\n",
       " '`concert_singer.singer`.Age': 9,\n",
       " '`concert_singer.singer`.Name': 10,\n",
       " '`concert_singer.singer`.Song_Name': 11,\n",
       " '`concert_singer.singer`.Is_male': 12,\n",
       " '`concert_singer.singer`.Singer_ID': 13,\n",
       " '`concert_singer.singer`.Song_release_year': 14,\n",
       " '`concert_singer.concert`.Theme': 15,\n",
       " '`concert_singer.concert`.Stadium_ID': 16,\n",
       " '`concert_singer.concert`.concert_Name': 17,\n",
       " '`concert_singer.concert`.concert_ID': 18,\n",
       " '`concert_singer.concert`.Year': 19,\n",
       " '`concert_singer.stadium`': 0,\n",
       " '`concert_singer.singer`': 1,\n",
       " '`concert_singer.concert`': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process_cypher import Schema, get_schema_from_json\n",
    "schema = Schema(get_schema_from_json(fpath, db_id))\n",
    "schema.idMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging Cypher parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_cypher import tokenize, scan_labels_with_alias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++tokenize++++++++++++++++++++++++++++++\n",
      "raw queries: ['MATCH (concert:`concert_singer.concert`)-[]-(T2:`concert_singer.stadium`)\\nWITH T2.Name AS Name, count(*) AS count ORDER BY T2.Name \\nRETURN Name,count'] <class 'list'>\n",
      "toks: [('Token.Keyword', 'MATCH'), ('Token.Text.Whitespace', ' '), ('Token.Punctuation', '('), ('Token.Name.Variable', 'concert'), ('Token.Punctuation', ':'), ('Token.Name.Label', '`concert_singer.concert`'), ('Token.Punctuation', ')-['), ('Token.Punctuation', ']-('), ('Token.Name.Variable', 'T2'), ('Token.Punctuation', ':'), ('Token.Name.Label', '`concert_singer.stadium`'), ('Token.Punctuation', ')'), ('Token.Keyword', 'WITH'), ('Token.Text.Whitespace', ' '), ('Token.Name.Variable', 'T2'), ('Token.Operator', '.'), ('Token.Keyword', 'Name'), ('Token.Text.Whitespace', ' '), ('Token.Keyword', 'AS'), ('Token.Text.Whitespace', ' '), ('Token.Keyword', 'Name'), ('Token.Punctuation', ','), ('Token.Text.Whitespace', ' '), ('Token.Name.Function', 'count'), ('Token.Punctuation', '('), ('Token.Operator', '*'), ('Token.Punctuation', ')'), ('Token.Text.Whitespace', ' '), ('Token.Keyword', 'AS'), ('Token.Text.Whitespace', ' '), ('Token.Name.Variable', 'count'), ('Token.Text.Whitespace', ' '), ('Token.Keyword', 'ORDER BY'), ('Token.Text.Whitespace', ' '), ('Token.Name.Variable', 'T2'), ('Token.Operator', '.'), ('Token.Keyword', 'Name'), ('Token.Text.Whitespace', ' \\n'), ('Token.Keyword', 'RETURN'), ('Token.Text.Whitespace', ' '), ('Token.Keyword', 'Name'), ('Token.Punctuation', ','), ('Token.Name.Variable', 'count')]\n"
     ]
    }
   ],
   "source": [
    "test_cypher = \"MATCH (concert:`concert_singer.concert`)-[]-(T2:`concert_singer.stadium`)\\nWITH T2.Name AS Name, count(*) AS count ORDER BY T2.Name \\nRETURN Name,count\"\n",
    "                   #\"match (n:`concert_singer.singer`) return count(*)\"\n",
    "toks = tokenize(test_cypher)\n",
    "print(f'toks: {toks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'concert': '`concert_singer.concert`', 'T2': '`concert_singer.stadium`', 'Name': ':`concert_singer.stadium`.Name'}\n"
     ]
    }
   ],
   "source": [
    "# test labels with alias\n",
    "labels_with_alias = scan_labels_with_alias(toks)\n",
    "print(labels_with_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "# test parse_cypher\n",
    "isBlock = False  #indicate if this is a block of cypher/subcypher\n",
    "len_ = len(toks)\n",
    "idx = start_idx\n",
    "toks_ = [tok[1].lower() for tok in toks]\n",
    "\n",
    "cypher = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from process_cypher import parse_cypher, parse_match, parse_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, toks_[idx]:match\n",
      "{'match': {'table_units': [('table_unit', 2), ('table_unit', 0)]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f'idx: {idx}, toks_[idx]:{toks_[idx]}')\n",
    "# parse from clause in order to get default tables\n",
    "match_end_idx, table_units, default_tables = parse_match(\n",
    "    toks, start_idx, labels_with_alias, schema\n",
    ")\n",
    "cypher['match']={'table_units': table_units}\n",
    "print(cypher)\n",
    "\n",
    "# parse 'with' clause\n",
    "idx = match_end_idx\n",
    "idx, with_units = parse_with(toks, idx, labels_with_alias, schema)\n",
    "cypher['with'] = with_units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'`concert_singer.stadium`'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_with_alias[toks[34][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test parse 'where' clause\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_col(toks, start_idx, labels_with_alias, schema, default_tables=None):\n",
    "    \"\"\"\n",
    "        :returns next idx, column id\n",
    "    \"\"\"\n",
    "    toks_ = [tok[1].lower() for tok in toks]\n",
    "    tok = toks_[start_idx]\n",
    "    if tok == \"*\":\n",
    "        return start_idx + 1, schema.idMap[tok]\n",
    "    print('ziiiiiii:', toks_[start_idx:])\n",
    "    print(toks[start_idx:])\n",
    "    if toks[start_idx][0] in ['Token.Punctuation', 'Token.Text.Whitespace' ]:\n",
    "        start_idx+=1\n",
    "    print('start_idx:', start_idx)\n",
    "    if '.' in toks_[start_idx:] and toks[start_idx][0]=='Token.Name.Variable':  # if token is a composite\n",
    "        print(tok)\n",
    "        key = labels_with_alias[toks[start_idx][1]]\n",
    "        schema_key = '{}.{}'.format(key, toks[start_idx+2][1])\n",
    "        return start_idx+2, schema.idMap[schema_key]\n",
    "\n",
    "    assert default_tables is not None and len(default_tables) > 0, \"Default tables should not be None or empty\"\n",
    "\n",
    "    for alias in default_tables:\n",
    "        table = labels_with_alias[alias]\n",
    "        table_original = table.strip('`').split('.')[-1]\n",
    "        if tok in schema.schema[table_original]:\n",
    "            key = table + \".\" + tok\n",
    "            return start_idx+1, schema.idMap[key]\n",
    "\n",
    "    assert False, \"Error col: {}\".format(tok)\n",
    "\n",
    "\n",
    "def parse_col_unit(toks, start_idx, labels_with_alias, schema, default_tables=None):\n",
    "    \"\"\"\n",
    "        :returns next idx, (agg_op id, col_id)\n",
    "    \"\"\"\n",
    "    toks_ = [tok[1].lower() for tok in toks]\n",
    "    idx = start_idx\n",
    "    len_ = len(toks)\n",
    "    # isBlock = False\n",
    "    isDistinct = False\n",
    "\n",
    "    # if toks_[idx] == '(':\n",
    "    #     isBlock = True\n",
    "    #     idx += 1\n",
    "    if toks[idx][0] in ['Token.Punctuation', 'Token.Text.Whitespace']:\n",
    "        idx += 1\n",
    "\n",
    "    if toks_[idx] in AGG_OPS:\n",
    "        agg_id = AGG_OPS.index(toks_[idx])\n",
    "        idx += 1\n",
    "        assert idx < len_ and toks_[idx] == '('\n",
    "        idx += 1\n",
    "        if toks_[idx] == \"distinct\":\n",
    "            idx += 1\n",
    "            isDistinct = True\n",
    "        idx, col_id = parse_col(toks, idx, labels_with_alias, schema, default_tables)\n",
    "        assert idx < len_ and toks_[idx] == ')'\n",
    "        idx += 1\n",
    "        return idx, (agg_id, col_id, isDistinct)\n",
    "\n",
    "    if toks_[idx] == \"distinct\":\n",
    "        idx += 1\n",
    "        isDistinct = True\n",
    "    agg_id = AGG_OPS.index(\"none\")\n",
    "    idx, col_id = parse_col(toks, idx, labels_with_alias, schema, default_tables)\n",
    "\n",
    "    # if isBlock:\n",
    "    #     assert toks_[idx] == ')'\n",
    "    #     idx += 1  # skip ')'\n",
    "\n",
    "    return idx, (agg_id, col_id, isDistinct)\n",
    "\n",
    "def parse_val_unit(toks, start_idx, labels_with_alias, schema, default_tables=None):\n",
    "    idx = start_idx\n",
    "    len_ = len(toks)\n",
    "    # isBlock = False\n",
    "    # if toks[idx] == '(':\n",
    "    #     isBlock = True\n",
    "    #     idx += 1\n",
    "\n",
    "    col_unit1 = None\n",
    "    col_unit2 = None\n",
    "    unit_op = UNIT_OPS.index('none')\n",
    "\n",
    "    idx, col_unit1 = parse_col_unit(toks, idx, labels_with_alias, schema, default_tables)\n",
    "    if idx < len_ and toks[idx] in UNIT_OPS:\n",
    "        unit_op = UNIT_OPS.index(toks[idx])\n",
    "        idx += 1\n",
    "        idx, col_unit2 = parse_col_unit(toks, idx, labels_with_alias, schema, default_tables)\n",
    "\n",
    "    # if isBlock:\n",
    "    #     assert toks[idx] == ')'\n",
    "    #     idx += 1  # skip ')'\n",
    "\n",
    "    return idx, (unit_op, col_unit1, col_unit2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Token.Text.Whitespace', ' '), ('Token.Name.Variable', 'T2'), ('Token.Operator', '.'), ('Token.Keyword', 'Name'), ('Token.Text.Whitespace', ' \\n'), ('Token.Keyword', 'RETURN'), ('Token.Text.Whitespace', ' '), ('Token.Keyword', 'Name'), ('Token.Punctuation', ','), ('Token.Name.Variable', 'count')]\n",
      "33\n",
      "ziiiiiii: ['t2', '.', 'name', ' \\n', 'return', ' ', 'name', ',', 'count']\n",
      "[('Token.Name.Variable', 'T2'), ('Token.Operator', '.'), ('Token.Keyword', 'Name'), ('Token.Text.Whitespace', ' \\n'), ('Token.Keyword', 'RETURN'), ('Token.Text.Whitespace', ' '), ('Token.Keyword', 'Name'), ('Token.Punctuation', ','), ('Token.Name.Variable', 'count')]\n",
      "start_idx: 34\n",
      "t2\n",
      "36 (0, 1, False)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m idx, col_unit1 \u001b[39m=\u001b[39m parse_col_unit(toks, idx, labels_with_alias, schema, default_tables)\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(idx, col_unit1)\n\u001b[0;32m---> 19\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m1\u001b[39m\u001b[39m>\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39m# isDistinct=False\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# print(toks_[idx])\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# if toks[idx][0] in ['Token.Punctuation', 'Token.Text.Whitespace' ]:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m# else:\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m#     break\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test parse 'order by' clause\n",
    "toks_ = [tok[1].lower() for tok in toks]\n",
    "len_ = len(toks)\n",
    "val_units = []  # (order_type, val_units), \\\n",
    "                    # where val_units = (unit_op, col_unit1, col_unit2), \\\n",
    "                    # and   col_unit=(agg_id, col_id, isDistinct), \\\n",
    "                    # and   col_id = schema.idMap[key]\n",
    "\n",
    "order_type = \"asc\"  # default type is 'asc'\n",
    "\n",
    "if idx>=len_ or toks_[idx]!='order by':\n",
    "    print(idx, val_units)\n",
    "\n",
    "idx+=1\n",
    "print(toks[idx:])\n",
    "while idx<len_ and not (toks_[idx] in CLAUSE_KEYWORDS or toks_[idx] in ( \";\")):\n",
    "    print(idx)\n",
    "    idx, val_unit = parse_val_unit(toks, idx, labels_with_alias, schema, default_tables)\n",
    "    val_units.append(val_unit)\n",
    "    if idx < len_ and toks_[idx] in ORDER_OPS:\n",
    "        order_type = toks_[idx]\n",
    "        idx += 1\n",
    "    if idx < len_ and toks[idx] == ',':\n",
    "        idx += 1  # skip ','\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_[idx-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_cypher import parse_val_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test parse 'return' clause\n",
    "# idx = start_idx\n",
    "len_ = len(toks)\n",
    "assert 'return' in toks_[idx:], \"'return' not found\"\n",
    "idx += 1\n",
    "isDistinct = False\n",
    "if idx < len_ and toks_[idx] == 'distinct':\n",
    "    idx += 1\n",
    "    isDistinct = True\n",
    "val_units = []\n",
    "print(idx, toks[idx:])\n",
    "while idx < len_ and toks_[idx] not in CLAUSE_KEYWORDS:\n",
    "    agg_id = AGG_OPS.index(\"none\")\n",
    "    if toks[idx] in AGG_OPS:\n",
    "        agg_id = AGG_OPS.index(toks[idx])\n",
    "        idx += 1\n",
    "    idx, val_unit = parse_val_unit(toks_, idx, labels_with_alias, schema, default_tables)\n",
    "\n",
    "    val_units.append((agg_id, val_unit))\n",
    "    if idx < len_ and toks_[idx] == ',':\n",
    "        idx += 1  # skip ','\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold0 = { \"query\": \"MATCH (t1:`concert_singer.singer`)\\n\\\n",
    "    WHERE t1.Song_Name =~'.*[H|h]ey.*'\\nRETURN t1.Name,t1.Country\",\n",
    "        \"question\": \"what is the name and nation of the singer who have a song having 'Hey' in its name?\",\n",
    "        \"schema_path\": \"/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/data/text2cypher/schema.json\",\n",
    "        \"db_id\": \"concert_singer\",\n",
    "        \"db_tag_names\": [\n",
    "            \":`concert_singer.stadium`\",\n",
    "            \":`concert_singer.singer`\",\n",
    "            \":`concert_singer.concert`\"\n",
    "        ],\n",
    "        \"db_property_names\": {\n",
    "            \"tag_id\": [\n",
    "                -1,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "                2,\n",
    "                2,\n",
    "                2,\n",
    "                2,\n",
    "                2\n",
    "            ],\n",
    "            \"property_name\": [\n",
    "                \"*\",\n",
    "                \"Name\",\n",
    "                \"Lowest\",\n",
    "                \"Stadium_ID\",\n",
    "                \"Capacity\",\n",
    "                \"Highest\",\n",
    "                \"Location\",\n",
    "                \"Average\",\n",
    "                \"Country\",\n",
    "                \"Age\",\n",
    "                \"Name\",\n",
    "                \"Song_Name\",\n",
    "                \"Is_male\",\n",
    "                \"Singer_ID\",\n",
    "                \"Song_release_year\",\n",
    "                \"Theme\",\n",
    "                \"Stadium_ID\",\n",
    "                \"concert_Name\",\n",
    "                \"concert_ID\",\n",
    "                \"Year\"\n",
    "            ]\n",
    "        },\n",
    "        \"db_property_types\": [\n",
    "            \"String\",\n",
    "            \"Long\",\n",
    "            \"Long\",\n",
    "            \"Long\",\n",
    "            \"Long\",\n",
    "            \"String\",\n",
    "            \"Long\",\n",
    "            \"String\",\n",
    "            \"Long\",\n",
    "            \"String\",\n",
    "            \"String\",\n",
    "            \"String\",\n",
    "            \"Long\",\n",
    "            \"String\",\n",
    "            \"String\",\n",
    "            \"String\",\n",
    "            \"String\",\n",
    "            \"Long\",\n",
    "            \"String\"\n",
    "        ],\n",
    "        \"serialized_schema\": \" | concert_singer | :`concert_singer.stadium` : Name , Lowest , Stadium_ID , Capacity , Highest , Location , Average | :`concert_singer.singer` : Country , Age , Name , Song_Name , Is_male , Singer_ID , Song_release_year | :`concert_singer.concert` : Theme , Stadium_ID , concert_Name , concert_ID , Year\",\n",
    "        \"struct_in\": \"| concert_singer | :`concert_singer.stadium` : Name , Lowest , Stadium_ID , Capacity , Highest , Location , Average | :`concert_singer.singer` : Country , Age , Name , Song_Name , Is_male , Singer_ID , Song_release_year | :`concert_singer.concert` : Theme , Stadium_ID , concert_Name , concert_ID , Year\",\n",
    "        \"text_in\": \"what is the name and nation of the singer who have a song having 'Hey' in its name?\",\n",
    "        \"seq_out\": \"MATCH (singer:`concert_singer.singer`) WHERE singer.Song_Name =~'.*[H|h]ey.*' RETURN singer.Name,singer.Country\",\n",
    "        \"description\": \"task: text-to-cypher\",\n",
    "        \"section\": \"test\",\n",
    "        \"arg_path\": \"META_TUNING/text2cypher_with_cell.cfg\"\n",
    "    }\n",
    "pred0 = \"MATCH (t1:`concert_singer.singer`) \\\n",
    "    WHERE t1.Song_Name =~'.*[Hey]?.*' RETURN t1.Name,t1.Nation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold0['struct_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks0 = tokenize(pred0)\n",
    "print(f'toks: {toks0}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold1 = {'query': 'MATCH (singer:`concert_singer.singer`)\\nWITH singer.Country AS Country, count(singer.Country) AS count\\nRETURN Country,count', 'question': 'How many singers are from each country?', 'schema_path': '/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/data/text2cypher/schema.json', 'db_id': 'concert_singer', 'db_tag_names': [':`concert_singer.stadium`', ':`concert_singer.singer`', ':`concert_singer.concert`'], 'db_property_names': {'tag_id': [-1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2], 'property_name': ['*', 'Name', 'Lowest', 'Stadium_ID', 'Capacity', 'Highest', 'Location', 'Average', 'Country', 'Age', 'Name', 'Song_Name', 'Is_male', 'Singer_ID', 'Song_release_year', 'Theme', 'Stadium_ID', 'concert_Name', 'concert_ID', 'Year']}, 'db_property_types': ['String', 'Long', 'Long', 'Long', 'Long', 'String', 'Long', 'String', 'Long', 'String', 'String', 'String', 'Long', 'String', 'String', 'String', 'String', 'Long', 'String'], 'serialized_schema': ' | concert_singer | :`concert_singer.stadium` : Name , Lowest , Stadium_ID , Capacity , Highest , Location , Average | :`concert_singer.singer` : Country , Age , Name , Song_Name , Is_male , Singer_ID , Song_release_year | :`concert_singer.concert` : Theme , Stadium_ID , concert_Name , concert_ID , Year', 'struct_in': '| concert_singer | :`concert_singer.stadium` : Name , Lowest , Stadium_ID , Capacity , Highest , Location , Average | :`concert_singer.singer` : Country , Age , Name , Song_Name , Is_male , Singer_ID , Song_release_year | :`concert_singer.concert` : Theme , Stadium_ID , concert_Name , concert_ID , Year', 'text_in': 'How many singers are from each country?', 'seq_out': 'MATCH (singer:`concert_singer.singer`) WITH singer.Country AS Country, count(singer.Country) AS count RETURN Country,count', 'description': 'task: text-to-cypher', 'section': 'test', 'arg_path': 'META_TUNING/text2cypher_with_cell.cfg'}\n",
    "pred1 = ' | concert_singer.singer| :`concert_singer.singer.stadium.singer.stadium.singer.stadium.singer.stadium.singer.singer.stadium.singer.singer.stadium.singer.singer.singer.stadium.singer.stadium.singer.singer.stadium.sing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold2 = {'query': 'MATCH (tv_series:`tvshow.TV_series`)\\nRETURN tv_series.Episode,tv_series.Rating\\nORDER BY tv_series.Rating DESC\\nLIMIT 3', 'question': \"List top 3 highest Rating  TV series. List the TV series's Episode and Rating.\", 'schema_path': '/home/22842219/Desktop/phd/SemanticParser4Graph/semantic_parser/data/text2cypher/schema.json', 'db_id': 'tvshow', 'db_tag_names': [':`tvshow.TV_Channel`', ':`tvshow.TV_series`', ':`tvshow.Cartoon`', ':`tvshow.TV_Channel_HAS_tvshow.TV_series`'], 'db_property_names': {'tag_id': [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2], 'property_name': ['*', 'Country', 'id', 'Package_Option', 'Language', 'Hight_definition_TV', 'Pixel_aspect_ratio_PAR', 'series_name', 'Pay_per_view_PPV', 'Content', 'id', 'Weekly_Rank', 'Episode', '18_49_Rating_Share', 'Rating', 'Share', 'Channel', 'Viewers_m', 'Air_Date', 'id', 'Title', 'Original_air_date', 'Production_code', 'Written_by', 'Directed_by', 'Channel']}, 'db_property_types': ['String', 'String', 'String', 'String', 'String', 'String', 'String', 'String', 'String', 'Double', 'Double', 'String', 'String', 'String', 'Double', 'String', 'String', 'String', 'Double', 'String', 'String', 'Double', 'String', 'String', 'String'], 'serialized_schema': ' | tvshow | :`tvshow.TV_Channel` : Country , id , Package_Option , Language , Hight_definition_TV , Pixel_aspect_ratio_PAR , series_name , Pay_per_view_PPV , Content | :`tvshow.TV_series` : id , Weekly_Rank , Episode , 18_49_Rating_Share , Rating , Share , Channel , Viewers_m , Air_Date | :`tvshow.Cartoon` : id , Title , Original_air_date , Production_code , Written_by , Directed_by , Channel | :`tvshow.TV_Channel_HAS_tvshow.TV_series` : ', 'struct_in': '| tvshow | :`tvshow.TV_Channel` : Country , id , Package_Option , Language , Hight_definition_TV , Pixel_aspect_ratio_PAR , series_name , Pay_per_view_PPV , Content | :`tvshow.TV_series` : id , Weekly_Rank , Episode , 18_49_Rating_Share , Rating , Share , Channel , Viewers_m , Air_Date | :`tvshow.Cartoon` : id , Title , Original_air_date , Production_code , Written_by , Directed_by , Channel | :`tvshow.TV_Channel_HAS_tvshow.TV_series` :', 'text_in': \"List top 3 highest Rating  TV series. List the TV series's Episode and Rating.\", 'seq_out': 'MATCH (tv_series:`tvshow.TV_series`) RETURN tv_series.Episode,tv_series.Rating ORDER BY tv_series.Rating DESC LIMIT 3', 'description': 'task: text-to-cypher', 'section': 'test', 'arg_path': 'META_TUNING/text2cypher_with_cell.cfg'}\n",
    "pred2 = 'SELECT * FROMTV_Series_Has_TVshow.TV_Series,,,,,,,: `tvshow.TV_Series_Has_TVshow.TV_Series_Has_TVshow.TV_Series_Has_TVshow.TV_Series_Has_TVshow.TV_Series_Has_TVshow.TV_Series_Has_TVshow.TV_Series_Has_TV'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

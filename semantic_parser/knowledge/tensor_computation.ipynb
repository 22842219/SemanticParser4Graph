{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 1.4554,  0.6291],\n",
      "        [-0.4008,  0.3982]])\n",
      "sum of main-diagonal elements (aka trace): 1.8536256551742554\n"
     ]
    }
   ],
   "source": [
    "# trace of a tensor (i.e. sum of main-diagonal elements)\n",
    "x = torch.randn(2,2)\n",
    "print(f'x: {x}')\n",
    "print(f\"sum of main-diagonal elements (aka trace): {torch.einsum('ii->', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.7136, -1.7813],\n",
      "        [-0.2499, -0.7382]])\n",
      "extract elements along the main-diagonal: tensor([ 0.7136, -0.7382])\n"
     ]
    }
   ],
   "source": [
    "# return a diagonal\n",
    "x = torch.randn(2,2)\n",
    "print(f'x: {x}')\n",
    "print(f\"extract elements along the main-diagonal: {torch.einsum('ii->i', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.5722, -0.9945,  1.2906],\n",
      "        [ 0.5316, -1.8923, -0.9052]])\n",
      "summations along axis1: tensor([ 0.8682, -2.2659])\n"
     ]
    }
   ],
   "source": [
    "# axis summations \n",
    "x = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f\"summations along axis1: {torch.einsum('ij->i', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-0.5291, -0.2948, -2.1050],\n",
      "        [-1.0407, -0.9205,  0.6792]])\n",
      "sum all elements: -4.210868835449219\n"
     ]
    }
   ],
   "source": [
    "# sum all elements \n",
    "x = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f\"sum all elements: {torch.einsum('ij->', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 1.0318,  1.4415,  1.4365],\n",
      "        [-1.0435,  1.1437, -0.4630]])\n",
      " matrix transpose: tensor([[ 1.0318, -1.0435],\n",
      "        [ 1.4415,  1.1437],\n",
      "        [ 1.4365, -0.4630]])\n"
     ]
    }
   ],
   "source": [
    "# transpositions and permutations\n",
    "x = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f\" matrix transpose: {torch.einsum('ij->ji', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.9742, -0.4430, -1.8800],\n",
      "        [ 0.5570, -1.7751,  0.2413]])\n",
      "y: tensor([[ 1.9212,  0.9515,  0.2009],\n",
      "        [-2.9630,  0.7491, -0.5690]])\n",
      "element-wise product: tensor([[ 1.8716, -0.4215, -0.3777],\n",
      "        [-1.6505, -1.3298, -0.1373]])\n"
     ]
    }
   ],
   "source": [
    "# Hadamard product (aka, element-wise product)\n",
    "x = torch.randn(2,3)\n",
    "y = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"element-wise product: {torch.einsum('ij, ij->ij', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[ 1.0526,  1.8596,  0.1192,  1.6131],\n",
      "         [-0.3572,  0.1965,  1.4893, -0.2191],\n",
      "         [ 0.9539,  1.4574,  0.0053,  0.5452]],\n",
      "\n",
      "        [[ 0.0578,  0.4697,  1.8059, -0.4695],\n",
      "         [-0.7423, -0.7920, -0.0337, -0.6462],\n",
      "         [-0.6740,  0.8839, -0.0392,  0.1205]]])\n",
      "y: tensor([[[-0.2666,  0.8063,  0.5379,  0.2846],\n",
      "         [ 1.2565, -0.5064, -0.4661,  1.6448],\n",
      "         [ 0.2930, -0.4391, -0.1996,  0.8416]],\n",
      "\n",
      "        [[ 0.1985,  0.4576,  0.2440,  1.2956],\n",
      "         [-0.7262,  0.2235,  0.5902,  2.4531],\n",
      "         [-0.0584,  0.1470,  0.6056,  0.7997]]])\n",
      "batch element-wise product: tensor([[[-2.8066e-01,  1.4994e+00,  6.4118e-02,  4.5915e-01],\n",
      "         [-4.4878e-01, -9.9515e-02, -6.9407e-01, -3.6037e-01],\n",
      "         [ 2.7951e-01, -6.3991e-01, -1.0505e-03,  4.5885e-01]],\n",
      "\n",
      "        [[ 1.1468e-02,  2.1495e-01,  4.4055e-01, -6.0824e-01],\n",
      "         [ 5.3908e-01, -1.7698e-01, -1.9891e-02, -1.5853e+00],\n",
      "         [ 3.9338e-02,  1.2992e-01, -2.3750e-02,  9.6343e-02]]])\n"
     ]
    }
   ],
   "source": [
    "# Batch Hadamard product (aka, batch element-wise product)\n",
    "x = torch.randn(2,3,4)\n",
    "y = torch.randn(2,3,4)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"batch element-wise product: {torch.einsum('ijk, ijk->ijk', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0526, 1.8596, 0.1192, 1.6131])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2666,  0.8063,  0.5379,  0.2846])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2807,  1.4994,  0.0641,  0.4591])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(x[0][0], y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-0.6970,  0.5416, -2.3438],\n",
      "        [-0.7064, -0.4908,  0.2314]])\n",
      "element-wise squaring: tensor([[0.4858, 0.2933, 5.4933],\n",
      "        [0.4991, 0.2409, 0.0536]])\n"
     ]
    }
   ],
   "source": [
    "#Element-wise squaring\n",
    "x = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f\"element-wise squaring: {torch.einsum('ij, ij->ij', x, x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[-0.6483, -0.2203,  1.7334, -0.1931],\n",
      "         [ 1.6125,  0.2170,  0.4474,  0.6518],\n",
      "         [ 0.5514,  0.7976,  0.8095, -0.1708]],\n",
      "\n",
      "        [[-0.2352, -0.6071,  0.0503, -0.0709],\n",
      "         [-0.0826, -0.5198, -1.7337, -0.1842],\n",
      "         [ 2.0146, -0.2615,  0.9516, -0.3381]]])\n",
      "batch element-wise squaring of 3D: tensor([[[4.2026e-01, 4.8525e-02, 3.0045e+00, 3.7298e-02],\n",
      "         [2.6000e+00, 4.7094e-02, 2.0021e-01, 4.2487e-01],\n",
      "         [3.0400e-01, 6.3618e-01, 6.5530e-01, 2.9176e-02]],\n",
      "\n",
      "        [[5.5330e-02, 3.6859e-01, 2.5348e-03, 5.0274e-03],\n",
      "         [6.8249e-03, 2.7020e-01, 3.0058e+00, 3.3919e-02],\n",
      "         [4.0586e+00, 6.8387e-02, 9.0555e-01, 1.1428e-01]]])\n"
     ]
    }
   ],
   "source": [
    "#batch element-wise squaring\n",
    "x = torch.randn(2,3,4)\n",
    "print(f'x: {x}')\n",
    "print(f\"batch element-wise squaring of 3D: {torch.einsum('ijk, ijk->ijk', x, x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 1.1797, -0.5684,  0.1082],\n",
      "        [ 0.8384, -1.0231, -1.7403]])\n",
      "y: tensor([[ 0.6265, -1.0299, -1.3438, -0.5172],\n",
      "        [ 0.1588, -1.0652, -0.8883, -1.4499],\n",
      "        [-1.8385, -1.2262,  1.2874, -0.3961]])\n",
      "matrix multiplication/aka dot product/aka inner product: tensor([[ 0.4497, -0.7422, -0.9409,  0.1712],\n",
      "        [ 3.5623,  2.3602, -2.4582,  1.7391]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication (aka dot product, aka scalar product, aka inner product)\n",
    "x = torch.randn(2,3)\n",
    "y = torch.randn(3,4)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"matrix multiplication/aka dot product/aka inner product: {torch.einsum('ij, jk->ik', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[ 0.1515, -0.3496,  0.7650,  0.6040],\n",
      "         [ 0.8685, -1.4364,  0.0914,  0.1212],\n",
      "         [ 0.3453, -0.2340, -0.3260,  0.5720]],\n",
      "\n",
      "        [[-2.8902,  0.6418, -0.0195,  1.2386],\n",
      "         [ 1.8281, -0.2336, -0.3397,  0.0692],\n",
      "         [-0.4830,  0.0451,  0.5253,  0.0101]]])\n",
      "y: tensor([[[ 0.1877, -1.3799, -0.2127, -0.6544, -0.0269],\n",
      "         [ 0.7993,  0.2086, -0.4630, -1.4449,  0.1118],\n",
      "         [ 0.7959, -0.0929, -0.0520, -0.0802, -1.0885],\n",
      "         [-0.3624,  0.3412,  0.6097,  0.0980, -0.2581]],\n",
      "\n",
      "        [[ 1.3594,  1.0189,  0.3122, -0.9438, -0.8878],\n",
      "         [ 0.6475, -0.9310, -0.0697, -0.9962,  0.6202],\n",
      "         [-1.4462, -0.1789, -1.3859, -0.1202,  0.8754],\n",
      "         [ 0.1682,  1.8850, -0.7201, -1.2129,  0.2301]]])\n",
      "batch matrix multiplication/aka batch dot product: tensor([[[ 0.1390, -0.1470,  0.4581,  0.4038, -1.0317],\n",
      "         [-0.9563, -1.4653,  0.5495,  1.5116, -0.3147],\n",
      "         [-0.5890, -0.2998,  0.4006,  0.1943,  0.1718]],\n",
      "\n",
      "        [[-3.2770, -1.2042, -1.8120,  0.5885,  3.2318],\n",
      "         [ 2.8369,  2.2713,  1.0081, -1.5358, -2.0492],\n",
      "         [-1.3855, -0.6092, -0.8893,  0.3355,  0.9190]]])\n"
     ]
    }
   ],
   "source": [
    "# batch matrix multiplication\n",
    "x = torch.randn(2,3,4)\n",
    "y = torch.randn(2,4,5)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"batch matrix multiplication/aka batch dot product: {torch.einsum('bij,bjk ->bik', x, y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1515, -0.3496,  0.7650,  0.6040])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1877,  0.7993,  0.7959, -0.3624])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1390)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x[0][0]*y[0].T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-1.0790, -0.1838, -1.1243],\n",
      "        [ 0.5787, -0.2924,  1.6458]])\n",
      "y: tensor([[ 0.4051, -1.7559,  0.0279],\n",
      "        [-0.0902, -0.5370, -0.5490]])\n",
      "double dot products: -0.9443585872650146\n"
     ]
    }
   ],
   "source": [
    "# double dot product/ Frobenius inner product (same as: torch.sum(hadamard-product))\n",
    "x = torch.randn(2,3)\n",
    "y = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"double dot products: {torch.einsum('ij,ij ->', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[ 0.8471,  0.6298, -1.0686,  0.6563],\n",
      "         [-0.9393,  0.0840,  0.2303,  0.4052],\n",
      "         [ 1.1011, -0.8386, -1.3216,  0.9700]],\n",
      "\n",
      "        [[ 1.7534, -0.6420,  0.8794, -0.1019],\n",
      "         [-0.0932,  1.1071,  0.2051,  0.8260],\n",
      "         [ 0.3092,  0.2295, -1.9509, -1.1938]]])\n",
      "y: tensor([[[ 1.7827, -0.4926,  1.2277,  0.5379],\n",
      "         [-0.1553, -0.6410, -0.9363, -1.0946],\n",
      "         [-2.5254, -1.0114,  0.9536, -0.2253]],\n",
      "\n",
      "        [[-0.5575,  0.4838,  0.5891,  0.1379],\n",
      "         [-0.3922, -0.6975, -0.9899,  2.2213],\n",
      "         [-0.7167, -0.0087,  0.0480, -0.4166]]])\n",
      ": tensor([[-1.1249,  0.4841, -2.7879, -0.3091],\n",
      "        [-1.1626, -1.0849,  0.2213,  2.3181]])\n"
     ]
    }
   ],
   "source": [
    "# Batch sum of element-wise product\n",
    "x = torch.randn(2,3,4)\n",
    "y = torch.randn(2,3,4)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\": {torch.einsum('bij,bij ->bj', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8471,  0.6298, -1.0686,  0.6563],\n",
       "        [-0.9393,  0.0840,  0.2303,  0.4052],\n",
       "        [ 1.1011, -0.8386, -1.3216,  0.9700]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7827, -0.4926,  1.2277,  0.5379],\n",
       "        [-0.1553, -0.6410, -0.9363, -1.0946],\n",
       "        [-2.5254, -1.0114,  0.9536, -0.2253]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1249,  0.4841, -2.7879, -0.3091])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.mul(x[0], y[0]), 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

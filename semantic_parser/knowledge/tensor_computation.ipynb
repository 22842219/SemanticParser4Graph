{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-0.9246,  0.5725],\n",
      "        [ 1.5614,  0.7287]])\n",
      "sum of main-diagonal elements (aka trace): -0.19591361284255981\n"
     ]
    }
   ],
   "source": [
    "# trace of a tensor (i.e. sum of main-diagonal elements)\n",
    "x = torch.randn(2,2)\n",
    "print(f'x: {x}')\n",
    "print(f\"sum of main-diagonal elements (aka trace): {torch.einsum('ii->', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-1.2552, -1.5755],\n",
      "        [-0.4351, -1.1378]])\n",
      "extract elements along the main-diagonal: tensor([-1.2552, -1.1378])\n"
     ]
    }
   ],
   "source": [
    "# return a diagonal\n",
    "x = torch.randn(2,2)\n",
    "print(f'x: {x}')\n",
    "print(f\"extract elements along the main-diagonal: {torch.einsum('ii->i', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-0.6573, -2.6793,  0.5065],\n",
      "        [-1.2995,  1.0958, -1.0628]])\n",
      "summations along axis1: tensor([-2.8301, -1.2666])\n"
     ]
    }
   ],
   "source": [
    "# axis summations \n",
    "x = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f\"summations along axis1: {torch.einsum('ij->i', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 1.1395,  0.1412,  0.4186],\n",
      "        [-1.3967,  1.1091,  1.7122]])\n",
      "sum all elements: 3.1238160133361816\n"
     ]
    }
   ],
   "source": [
    "# sum all elements \n",
    "x = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f\"sum all elements: {torch.einsum('ij->', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-0.7484,  0.4253,  0.0512],\n",
      "        [ 0.8153, -0.2533,  1.1448]])\n",
      " matrix transpose: tensor([[-0.7484,  0.8153],\n",
      "        [ 0.4253, -0.2533],\n",
      "        [ 0.0512,  1.1448]])\n"
     ]
    }
   ],
   "source": [
    "# transpositions and permutations\n",
    "x = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f\" matrix transpose: {torch.einsum('ij->ji', x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 1.9482, -0.4157,  0.5294],\n",
      "        [-0.4393,  0.6180, -0.7716]])\n",
      "y: tensor([[ 1.0552, -1.9182,  0.4017],\n",
      "        [ 0.4868, -0.0984, -1.6488]])\n",
      "element-wise product: tensor([[ 2.0558,  0.7973,  0.2126],\n",
      "        [-0.2139, -0.0608,  1.2723]])\n"
     ]
    }
   ],
   "source": [
    "# Hadamard product (aka, element-wise product)\n",
    "x = torch.randn(2,3)\n",
    "y = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"element-wise product: {torch.einsum('ij, ij->ij', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[-0.4088,  0.4388, -0.0113,  0.2040],\n",
      "         [ 0.1149, -0.8467, -0.5215, -0.3189],\n",
      "         [-0.8025,  0.6985,  1.9038,  0.4198]],\n",
      "\n",
      "        [[-0.1224,  0.4112,  1.8690, -0.8694],\n",
      "         [ 0.4843, -1.6301, -0.4105, -0.0347],\n",
      "         [-0.3375,  0.4601, -2.0345,  0.4969]]])\n",
      "y: tensor([[[ 0.9675, -1.9007,  0.5053,  0.8311],\n",
      "         [-0.0776, -0.5151,  0.4124,  0.9237],\n",
      "         [ 1.0182, -0.5842,  0.8982,  2.0471]],\n",
      "\n",
      "        [[-0.2510, -0.1995,  0.6869, -0.1266],\n",
      "         [ 0.2144,  0.9323, -1.3991, -1.6575],\n",
      "         [-0.4247,  1.5779,  0.5201, -0.3391]]])\n",
      "batch element-wise product: tensor([[[-0.3955, -0.8340, -0.0057,  0.1695],\n",
      "         [-0.0089,  0.4361, -0.2151, -0.2945],\n",
      "         [-0.8171, -0.4080,  1.7100,  0.8593]],\n",
      "\n",
      "        [[ 0.0307, -0.0820,  1.2837,  0.1100],\n",
      "         [ 0.1038, -1.5198,  0.5744,  0.0575],\n",
      "         [ 0.1433,  0.7259, -1.0581, -0.1685]]])\n"
     ]
    }
   ],
   "source": [
    "# Batch Hadamard product (aka, batch element-wise product)\n",
    "x = torch.randn(2,3,4)\n",
    "y = torch.randn(2,3,4)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"batch element-wise product: {torch.einsum('ijk, ijk->ijk', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4088,  0.4388, -0.0113,  0.2040])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9675, -1.9007,  0.5053,  0.8311])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3955, -0.8340, -0.0057,  0.1695])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(x[0][0], y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-0.8581,  0.7851, -2.1807],\n",
      "        [ 0.5431,  1.8429, -0.4270]])\n",
      "element-wise squaring: tensor([[0.7364, 0.6164, 4.7555],\n",
      "        [0.2950, 3.3962, 0.1823]])\n"
     ]
    }
   ],
   "source": [
    "#Element-wise squaring\n",
    "x = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f\"element-wise squaring: {torch.einsum('ij, ij->ij', x, x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[-1.2866,  0.7288,  0.9549, -0.0288],\n",
      "         [ 0.8938,  1.3885,  0.5825, -1.0367],\n",
      "         [-0.0518,  1.2771, -0.2792, -0.4933]],\n",
      "\n",
      "        [[-0.1655, -1.3628, -0.3494,  2.0258],\n",
      "         [ 0.1322, -0.3116,  0.5265, -1.5448],\n",
      "         [ 0.6981, -1.0780,  1.0337,  2.4459]]])\n",
      "batch element-wise squaring of 3D: tensor([[[1.6553e+00, 5.3116e-01, 9.1193e-01, 8.2992e-04],\n",
      "         [7.9893e-01, 1.9278e+00, 3.3927e-01, 1.0747e+00],\n",
      "         [2.6847e-03, 1.6309e+00, 7.7980e-02, 2.4335e-01]],\n",
      "\n",
      "        [[2.7405e-02, 1.8571e+00, 1.2207e-01, 4.1040e+00],\n",
      "         [1.7477e-02, 9.7080e-02, 2.7716e-01, 2.3865e+00],\n",
      "         [4.8736e-01, 1.1620e+00, 1.0685e+00, 5.9826e+00]]])\n"
     ]
    }
   ],
   "source": [
    "#batch element-wise squaring\n",
    "x = torch.randn(2,3,4)\n",
    "print(f'x: {x}')\n",
    "print(f\"batch element-wise squaring of 3D: {torch.einsum('ijk, ijk->ijk', x, x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.1936,  0.5547,  0.3681],\n",
      "        [ 1.8390,  1.0020, -1.1445]])\n",
      "y: tensor([[-1.3602,  0.2244, -0.3784, -0.3083],\n",
      "        [-0.6085, -0.7188,  0.2970, -0.2583],\n",
      "        [-0.0902, -0.5231,  0.3228,  0.9014]])\n",
      "matrix multiplication/aka dot product/aka inner product: tensor([[-0.6341, -0.5478,  0.2103,  0.1289],\n",
      "        [-3.0079,  0.2911, -0.7676, -1.8574]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication (aka dot product, aka scalar product, aka inner product)\n",
    "x = torch.randn(2,3)\n",
    "y = torch.randn(3,4)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"matrix multiplication/aka dot product/aka inner product: {torch.einsum('ij, jk->ik', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[ 0.1046,  1.1601, -1.3931, -0.3127],\n",
      "         [ 1.4275, -1.3718,  0.6854, -1.2418],\n",
      "         [ 0.1169,  0.0023,  0.8855,  0.0998]],\n",
      "\n",
      "        [[-0.5069, -0.6111, -0.9057, -1.5333],\n",
      "         [-0.0666,  1.0754, -1.2889, -1.4844],\n",
      "         [-0.6905, -0.4721, -0.9851, -0.7915]]])\n",
      "y: tensor([[[-0.9000, -0.6691, -1.6288, -0.4369,  0.1838],\n",
      "         [ 1.0008,  0.2858,  0.3163,  0.0715,  1.7307],\n",
      "         [-1.0459, -1.0507, -1.2698, -0.1862,  1.3261],\n",
      "         [ 0.5438,  0.1990, -0.5217,  0.0895,  0.1649]],\n",
      "\n",
      "        [[-0.3631, -0.1758, -0.2286, -0.9361, -1.3516],\n",
      "         [-0.2695, -0.4870, -1.4853,  2.0657, -0.4406],\n",
      "         [-0.1402,  0.3775,  1.2639, -0.9296, -0.2855],\n",
      "         [ 1.2885,  0.0359,  0.6569, -0.1324, -0.6414]]])\n",
      "batch matrix multiplication/aka batch dot product: tensor([[[ 2.3539,  1.6631,  2.1286,  0.2686,  0.1281],\n",
      "         [-4.0497, -2.3144, -2.9815, -0.9605, -1.4077],\n",
      "         [-0.9748, -0.9881, -1.3662, -0.2068,  1.2162]],\n",
      "\n",
      "        [[-1.5000, -0.0102, -1.1284,  0.2571,  2.1964],\n",
      "         [-1.9976, -1.0519, -4.1863,  3.6786,  0.9362],\n",
      "         [-0.5038, -0.0489, -0.9059,  0.6917,  1.9302]]])\n"
     ]
    }
   ],
   "source": [
    "# batch matrix multiplication\n",
    "x = torch.randn(2,3,4)\n",
    "y = torch.randn(2,4,5)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"batch matrix multiplication/aka batch dot product: {torch.einsum('bij,bjk ->bik', x, y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1046,  1.1601, -1.3931, -0.3127])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9000,  1.0008, -1.0459,  0.5438])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3539)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x[0][0]*y[0].T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-0.8592,  0.6566,  0.7164],\n",
      "        [-1.0285, -1.2278, -0.5428]])\n",
      "y: tensor([[-1.4377,  0.9829,  0.9472],\n",
      "        [ 1.2654, -0.3706,  0.1436]])\n",
      "double dot products: 1.6347986459732056\n"
     ]
    }
   ],
   "source": [
    "# double dot product/ Frobenius inner product (same as: torch.sum(hadamard-product))\n",
    "x = torch.randn(2,3)\n",
    "y = torch.randn(2,3)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"double dot products: {torch.einsum('ij,ij ->', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[ 0.1832,  1.0843, -1.1946, -0.8681],\n",
      "         [-0.9427,  0.2572, -0.1599, -0.6560],\n",
      "         [-0.9601,  0.3200,  0.7864,  0.3208]],\n",
      "\n",
      "        [[ 1.0330, -0.8597, -2.4755, -0.1428],\n",
      "         [-0.8975, -0.8498, -1.0475,  0.1290],\n",
      "         [ 1.7242, -0.0284, -0.0817, -1.3094]]])\n",
      "y: tensor([[[ 0.0761,  0.4934,  1.0517,  0.3773],\n",
      "         [-0.9937, -0.0217, -0.2790,  1.3316],\n",
      "         [ 1.8066,  0.1890,  1.5630,  0.5897]],\n",
      "\n",
      "        [[-0.1358,  0.2856,  0.5682,  0.6544],\n",
      "         [-0.9042,  0.3156, -0.4115,  0.9386],\n",
      "         [-0.2048,  0.7711,  1.0042, -1.0369]]])\n",
      "Batch sum of element-wise product along the first dimension (axis=1): tensor([[-0.7839,  0.5898,  0.0174, -1.0119],\n",
      "        [ 0.3182, -0.5356, -1.0577,  1.3853]])\n"
     ]
    }
   ],
   "source": [
    "# Batch sum of element-wise product along axis\n",
    "x = torch.randn(2,3,4)\n",
    "y = torch.randn(2,3,4)\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')\n",
    "print(f\"Batch sum of element-wise product along the first dimension (axis=1): {torch.einsum('bij,bij ->bj', x, y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1832,  1.0843, -1.1946, -0.8681],\n",
       "        [-0.9427,  0.2572, -0.1599, -0.6560],\n",
       "        [-0.9601,  0.3200,  0.7864,  0.3208]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0761,  0.4934,  1.0517,  0.3773],\n",
       "        [-0.9937, -0.0217, -0.2790,  1.3316],\n",
       "        [ 1.8066,  0.1890,  1.5630,  0.5897]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4747, 0.1943, 0.6307, 0.1314])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.mul(x[0], y[0]), 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
